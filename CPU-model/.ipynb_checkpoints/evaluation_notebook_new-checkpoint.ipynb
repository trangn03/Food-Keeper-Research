{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacaef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ## Evaluation Notebook\n",
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "#pip install spacy\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import re\n",
    "import os\n",
    "from spacy import displacy\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "FOODKEEPER_PATH = \"datasets/FoodKeeper-Data.xls\"\n",
    "TRAINING_DATA_PATH = \"datasets/data.csv\"\n",
    "MODEL_PATH = \"output/model-last\"\n",
    "TEST_DATA_PATH = \"datasets/test_data.csv\"\n",
    "REAL_TWITTER_DATA_PATH = \"datasets/data.csv\"\n",
    "NEW_TWITTER_DATA = \"datasets/new_test_tweets.csv\"\n",
    "#STARTING_KEYWORD_COUNT = 10\n",
    "#TRAINING_LOOP_ITERATIONS = 3\n",
    "#REQUIRED_KEYWORDS = 3\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b58b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_data = pd.read_excel(FOODKEEPER_PATH, sheet_name = \"Product\")\n",
    "all_data = pd.read_csv(TRAINING_DATA_PATH,index_col = False, header = None)\n",
    "#live_tweets = pd.read_csv(REAL_TWITTER_DATA_PATH, header = None)  \n",
    "    \n",
    "#Gathers all the keywords from the FoodKeeper database\n",
    "def foodKeeperInfo():\n",
    "    keywords = []\n",
    "    for word in food_data['Name']: # food_data['Keywords']:\n",
    "        word = word.replace(\" or \", \" \") # TO DO: break up phrases with commas like \"Pastries, danish\" into separate words\n",
    "        # word = word.split(\",\")\n",
    "            # for w in words:\n",
    "                # w = w.strip() - remove leading and trailing whitespace\n",
    "                # if w not in keywords:\n",
    "                    # keywords.append(w)\n",
    "        word = re.sub('[/,]', ' ', word)\n",
    "        word = word.lstrip()\n",
    "        word = word.rstrip()\n",
    "        if word.lower() not in keywords: \n",
    "            keywords.append(word.lower())\n",
    "\n",
    "    #print(\"Total foodkeeper food names: \" + str(len(keywords)))        \n",
    "    #for element in sorted(keywords):\n",
    "        #print(element)\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def preProcess(tweet):\n",
    "    #Converts a tweet to lowercase, replaces anyusername w/ <USERNAME> and URLS with <URL>\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('@[a-zA-z0-9]*', '', tweet)              # <USERNAME>\n",
    "    tweet = re.sub('http[a-zA-z0-9./:]*', '', tweet)       # <URL>\n",
    "    tweet = re.sub('[.,-]*', '', tweet)\n",
    "    tweet = re.sub('&amp;', 'and', tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "foodKeeperKeywords = foodKeeperInfo()\n",
    "print(foodKeeperKeywords)\n",
    "\n",
    "for i in range(len(all_data[0])):\n",
    "     all_data[0][i] = preProcess(all_data[0][i])\n",
    "\n",
    "# TO BE COMPLETED: \n",
    "# select tweets which contain one of the foodKeeperKeywords\n",
    "selected_tweets = all_data[all_data[0].str.find('|'.join(foodKeeperKeywords)) != -1] # contains\n",
    "# then select 250 random tweets of these; this is the test_data\n",
    "test_data = selected_tweets.sample(all_data, 250) \n",
    "# save test_data in a \"new_test_tweets.csv\" file\n",
    "test_data.to_csv('new_test_tweets.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d512732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code with spacy\n",
    "\n",
    "    \n",
    "def ent_recognize(text):\n",
    "    doc = nlp(text)\n",
    "    displacy.render(doc,style = \"ent\")\n",
    "    \n",
    "def predict(tweet):\n",
    "    doc = nlp(str(tweet))\n",
    "    if doc.ents:\n",
    "        displacy.render(doc,style = \"ent\")\n",
    "\n",
    "def returnPrediction(tweet):\n",
    "    nlp = spacy.load(MODEL_PATH)\n",
    "    doc = nlp(str(tweet))\n",
    "    if doc.ents:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_predictions():\n",
    "    predictions = []\n",
    "    for tweet in test_data['tweet'].tolist():\n",
    "        predictions.append(returnPrediction(tweet))\n",
    "    return predictions\n",
    "    \n",
    "def eval_model():\n",
    "    nlp = spacy.load(MODEL_PATH)\n",
    "    predictions = get_predictions()\n",
    "    print(metrics.confusion_matrix(y,predictions, labels = [1,0]))\n",
    "    print(metrics.classification_report(y,predictions, labels = [1,0]))\n",
    "    \n",
    "def show_tp():\n",
    "    counter = 0\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    predictions = get_predictions()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 1 and y[i] == 1:\n",
    "            print(\"True positives:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_tn():\n",
    "    counter = 0\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 0 and y[i] == 0:\n",
    "            print(\"True Negative:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_fn():\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet']\n",
    "    counter = 0\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 0 and y[i] == 1:\n",
    "            print(\"False Negative:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_fp():\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 1 and y[i] == 0:\n",
    "            print(\"False Positive:\")\n",
    "            doc = nlp(str(tweets[i]))\n",
    "            if doc.ents:\n",
    "                displacy.render(doc,style = \"ent\")\n",
    "\n",
    "# Evaluation: how well does the existing spacy model identify foods\n",
    "# Read \"new_test_tweets.csv\",  \n",
    "\n",
    "test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "#test_data = pd.read_csv(\"datasets/new_test_tweets.csv\")\n",
    "\n",
    "#y = test_data['food'].tolist()\n",
    "nlp = spacy.load(MODEL_PATH)\n",
    "#nlp = spacy.blank(\"en\")\n",
    "print(nlp.pipe_names)\n",
    "ent_recognize(\"My rice cakes is tasty\")\n",
    "ent_recognize(\" peanut butter and jelly is the classic for me stuff that includes fruit sugars (like apples) are a good choice too imo\")\n",
    "\n",
    "\n",
    "# # Checking for overlapping words\n",
    "   \n",
    "#     print(data)\n",
    "# keywords = foodKeeperInfo()\n",
    "# testdata = convertToTrainingFormat(\"My rice cakes is tasty \", keywords)\n",
    "\n",
    "# # for word in keywords:\n",
    "# #     for word2 in wordsInFoodkeeper:\n",
    "# #         if word in word2 and word != word2:\n",
    "# #             print(word,word2)\n",
    "\n",
    "\n",
    "\n",
    "# ## Use the function below to check individual sentences\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# ent_recognize(\"my friend is chicken because he is scared\")\n",
    "# print(live_tweets)\n",
    "# testTweets = live_tweets[5]\n",
    "# for tweet in testTweets[:500]:\n",
    "#     if nlp(preProcess(tweet)).ents:\n",
    "#         ent_recognize(preProcess(tweet))\n",
    "\n",
    "\n",
    "# ## Use the function below to check model performance on the entire test set\n",
    "eval_model()\n",
    "\n",
    "# ## Use the functions below to see TP, TN, FP, FN respectively\n",
    "# show_tp()\n",
    "# show_tn()\n",
    "# show_fp()\n",
    "#show_fn()\n",
    "\n",
    "# foodkeeper = foodKeeperInfo()\n",
    "# print(foodkeeper)\n",
    "# sortedKeywords =  sorted(keywordRanker, key=keywordRanker.get, reverse=True)\n",
    "\n",
    "# for i in range(15): #sortedKeywords\n",
    "#     keywords.append(sortedKeywords[i])\n",
    "# print(keywords)\n",
    "# keywords.append(\"chicken\")\n",
    "# #keywords.append(\"cream cheese\")\n",
    "\n",
    "# abc = convertToTrainingFormat(\"I like to eat cream and cheese with chicken test\", keywords)\n",
    "# print(abc)\n",
    "\n",
    "# # See what keywords are found by the created model\n",
    "# keywordsFound = []\n",
    "# nlp = spacy.load(MODEL_PATH)\n",
    "# print(nlp.pipeline)\n",
    "# for tweet in live_tweets[5]: #test_data['tweet']:\n",
    "#     modeledTweet = nlp(preProcess(tweet))\n",
    "#     for token in modeledTweet.doc.ents:\n",
    "#         if str(token) in keywordsFound: continue\n",
    "#         keywordsFound.append(str(token))\n",
    "\n",
    "\n",
    "# # If the model finds food keywords print the Tweet\n",
    "# To help visualize which keywords are being found this loop iterates through the Tweets testing the model to see what keywords it finds. If it finds a keyword in the Tweet it will print the Tweet and highlight the keyword\n",
    "\n",
    "# for tweet in test_data['tweet'][:500]:\n",
    "#     ents = nlp(preProcess(tweet))\n",
    "#     #if ents.doc.ents:\n",
    "#     ent_recognize(preProcess(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a29010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
