{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacaef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ## Evaluation Notebook\n",
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "#pip install spacy\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import re\n",
    "import os\n",
    "from spacy import displacy\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "FOODKEEPER_PATH = \"datasets/FoodKeeper-Data.xls\"\n",
    "TRAINING_DATA_PATH = \"datasets/data.csv\"\n",
    "MODEL_PATH = \"output/model-last\"\n",
    "TEST_DATA_PATH = \"datasets/test_data.csv\"\n",
    "REAL_TWITTER_DATA_PATH = \"datasets/data.csv\"\n",
    "#STARTING_KEYWORD_COUNT = 10\n",
    "#TRAINING_LOOP_ITERATIONS = 3\n",
    "#REQUIRED_KEYWORDS = 3\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b58b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_data = pd.read_excel(FOODKEEPER_PATH, sheet_name = \"Product\")\n",
    "all_data = pd.read_csv(TRAINING_DATA_PATH,index_col = False, header = None)\n",
    "#live_tweets = pd.read_csv(REAL_TWITTER_DATA_PATH, header = None)  \n",
    "    \n",
    "#Gathers all the keywords from the FoodKeeper database\n",
    "def foodKeeperInfo():\n",
    "    keywords = []\n",
    "    for word in food_data['Name']: # food_data['Keywords']:\n",
    "        word = word.replace(\" or \", \" \") # TO DO: break up phrases with commas like \"Pastries, danish\" into separate words\n",
    "        word = re.sub('[/,]', ' ', word)\n",
    "        word = word.lstrip()\n",
    "        word = word.rstrip()\n",
    "        if word.lower() not in keywords: \n",
    "            keywords.append(word.lower())\n",
    "\n",
    "    #print(\"Total foodkeeper food names: \" + str(len(keywords)))        \n",
    "    #for element in sorted(keywords):\n",
    "        #print(element)\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def preProcess(tweet):\n",
    "    #Converts a tweet to lowercase, replaces anyusername w/ <USERNAME> and URLS with <URL>\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('@[a-zA-z0-9]*', '', tweet)              # <USERNAME>\n",
    "    tweet = re.sub('http[a-zA-z0-9./:]*', '', tweet)       # <URL>\n",
    "    tweet = re.sub('[.,-]*', '', tweet)\n",
    "    tweet = re.sub('&amp;', 'and', tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "foodKeeperKeywords = foodKeeperInfo()\n",
    "print(foodKeeperKeywords)\n",
    "\n",
    "for i in range(len(all_data[0])):\n",
    "     all_data[0][i] = preProcess(all_data[0][i])\n",
    "\n",
    "# TO BE COMPLETED: \n",
    "# select tweets which contain one of the foodKeeperKeywords\n",
    "# then select 250 random tweets of these; this is the test_data\n",
    "# save test_data in a \"new_test_tweets.csv\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d512732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apanangadan\\AppData\\Local\\anaconda3\\lib\\site-packages\\spacy\\util.py:887: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.5.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'ner']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rice\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " cakes is tasty</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    peanut butter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " and jelly is the classic for me stuff that includes \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fruit\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " sugars (like apples) are a good choice too imo</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 156\u001b[0m\n\u001b[0;32m    129\u001b[0m ent_recognize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m peanut butter and jelly is the classic for me stuff that includes fruit sugars (like apples) are a good choice too imo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# # Checking for overlapping words\u001b[39;00m\n\u001b[0;32m    133\u001b[0m    \n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#     print(data)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# ## Use the function below to check model performance on the entire test set\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 75\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(MODEL_PATH)\n\u001b[0;32m     74\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions()\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(\u001b[43my\u001b[49m,predictions, labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mclassification_report(y,predictions, labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# code with spacy\n",
    "\n",
    "    \n",
    "def ent_recognize(text):\n",
    "    doc = nlp(text)\n",
    "    displacy.render(doc,style = \"ent\")\n",
    "    \n",
    "def predict(tweet):\n",
    "    doc = nlp(str(tweet))\n",
    "    if doc.ents:\n",
    "        displacy.render(doc,style = \"ent\")\n",
    "\n",
    "def returnPrediction(tweet):\n",
    "    nlp = spacy.load(MODEL_PATH)\n",
    "    doc = nlp(str(tweet))\n",
    "    if doc.ents:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_predictions():\n",
    "    predictions = []\n",
    "    for tweet in test_data['tweet'].tolist():\n",
    "        predictions.append(returnPrediction(tweet))\n",
    "    return predictions\n",
    "    \n",
    "def eval_model():\n",
    "    nlp = spacy.load(MODEL_PATH)\n",
    "    predictions = get_predictions()\n",
    "    print(metrics.confusion_matrix(y,predictions, labels = [1,0]))\n",
    "    print(metrics.classification_report(y,predictions, labels = [1,0]))\n",
    "    \n",
    "def show_tp():\n",
    "    counter = 0\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    predictions = get_predictions()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 1 and y[i] == 1:\n",
    "            print(\"True positives:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_tn():\n",
    "    counter = 0\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 0 and y[i] == 0:\n",
    "            print(\"True Negative:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_fn():\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet']\n",
    "    counter = 0\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 0 and y[i] == 1:\n",
    "            print(\"False Negative:\", tweets[i], \"\\n\")\n",
    "            counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "def show_fp():\n",
    "    predictions = get_predictions()\n",
    "    tweets = test_data['tweet'].tolist()\n",
    "    for i in range(len(y)):\n",
    "        if predictions[i] == 1 and y[i] == 0:\n",
    "            print(\"False Positive:\")\n",
    "            doc = nlp(str(tweets[i]))\n",
    "            if doc.ents:\n",
    "                displacy.render(doc,style = \"ent\")\n",
    "\n",
    "# Evaluation: how well does the existing spacy model identify foods\n",
    "# Read \"new_test_tweets.csv\",  \n",
    "\n",
    "test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "#test_data = pd.read_csv(\"datasets/new_test_tweets.csv\")\n",
    "\n",
    "#y = test_data['food'].tolist()\n",
    "nlp = spacy.load(MODEL_PATH)\n",
    "#nlp = spacy.blank(\"en\")\n",
    "print(nlp.pipe_names)\n",
    "ent_recognize(\"My rice cakes is tasty\")\n",
    "ent_recognize(\" peanut butter and jelly is the classic for me stuff that includes fruit sugars (like apples) are a good choice too imo\")\n",
    "\n",
    "\n",
    "# # Checking for overlapping words\n",
    "   \n",
    "#     print(data)\n",
    "# keywords = foodKeeperInfo()\n",
    "# testdata = convertToTrainingFormat(\"My rice cakes is tasty \", keywords)\n",
    "\n",
    "# # for word in keywords:\n",
    "# #     for word2 in wordsInFoodkeeper:\n",
    "# #         if word in word2 and word != word2:\n",
    "# #             print(word,word2)\n",
    "\n",
    "\n",
    "\n",
    "# ## Use the function below to check individual sentences\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# ent_recognize(\"my friend is chicken because he is scared\")\n",
    "# print(live_tweets)\n",
    "# testTweets = live_tweets[5]\n",
    "# for tweet in testTweets[:500]:\n",
    "#     if nlp(preProcess(tweet)).ents:\n",
    "#         ent_recognize(preProcess(tweet))\n",
    "\n",
    "\n",
    "# ## Use the function below to check model performance on the entire test set\n",
    "eval_model()\n",
    "\n",
    "# ## Use the functions below to see TP, TN, FP, FN respectively\n",
    "# show_tp()\n",
    "# show_tn()\n",
    "# show_fp()\n",
    "#show_fn()\n",
    "\n",
    "# foodkeeper = foodKeeperInfo()\n",
    "# print(foodkeeper)\n",
    "# sortedKeywords =  sorted(keywordRanker, key=keywordRanker.get, reverse=True)\n",
    "\n",
    "# for i in range(15): #sortedKeywords\n",
    "#     keywords.append(sortedKeywords[i])\n",
    "# print(keywords)\n",
    "# keywords.append(\"chicken\")\n",
    "# #keywords.append(\"cream cheese\")\n",
    "\n",
    "# abc = convertToTrainingFormat(\"I like to eat cream and cheese with chicken test\", keywords)\n",
    "# print(abc)\n",
    "\n",
    "# # See what keywords are found by the created model\n",
    "# keywordsFound = []\n",
    "# nlp = spacy.load(MODEL_PATH)\n",
    "# print(nlp.pipeline)\n",
    "# for tweet in live_tweets[5]: #test_data['tweet']:\n",
    "#     modeledTweet = nlp(preProcess(tweet))\n",
    "#     for token in modeledTweet.doc.ents:\n",
    "#         if str(token) in keywordsFound: continue\n",
    "#         keywordsFound.append(str(token))\n",
    "\n",
    "\n",
    "# # If the model finds food keywords print the Tweet\n",
    "# To help visualize which keywords are being found this loop iterates through the Tweets testing the model to see what keywords it finds. If it finds a keyword in the Tweet it will print the Tweet and highlight the keyword\n",
    "\n",
    "# for tweet in test_data['tweet'][:500]:\n",
    "#     ents = nlp(preProcess(tweet))\n",
    "#     #if ents.doc.ents:\n",
    "#     ent_recognize(preProcess(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a29010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
